{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC2143dTHpNQ"
      },
      "source": [
        "# Soccer master\n",
        "\n",
        "## Model training\n",
        "\n",
        "This is the model training part of the project and for this you'll require the data file which is generated after running soccer_master_eda.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EyWfDvYWM_uR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from abc import ABC, abstractmethod\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VycNP1NSMLAc"
      },
      "source": [
        "# Pre-processed data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "kCRTe53YNOe8",
        "outputId": "8576eeb1-ee11-4e22-9f7c-90d3a36c90c4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>player_id</th>\n",
              "      <th>from_club_id</th>\n",
              "      <th>to_club_id</th>\n",
              "      <th>transfer_fee</th>\n",
              "      <th>market_value_in_eur</th>\n",
              "      <th>season</th>\n",
              "      <th>home_games</th>\n",
              "      <th>playing_formation</th>\n",
              "      <th>appearances</th>\n",
              "      <th>goals_per_game</th>\n",
              "      <th>...</th>\n",
              "      <th>win_percentage</th>\n",
              "      <th>draw_percentage</th>\n",
              "      <th>home_win_percentage</th>\n",
              "      <th>away_win_percentage</th>\n",
              "      <th>position</th>\n",
              "      <th>sub_position</th>\n",
              "      <th>foot</th>\n",
              "      <th>avg_market_value_of_last_seasons</th>\n",
              "      <th>age_at_transfer</th>\n",
              "      <th>transfer_diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3333</td>\n",
              "      <td>10161</td>\n",
              "      <td>399</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2002</td>\n",
              "      <td>35.0</td>\n",
              "      <td>4-2-3-1</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.263889</td>\n",
              "      <td>0.316993</td>\n",
              "      <td>0.088889</td>\n",
              "      <td>Goalkeeper</td>\n",
              "      <td>Goalkeeper</td>\n",
              "      <td>left</td>\n",
              "      <td>1.500000e+06</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3333</td>\n",
              "      <td>399</td>\n",
              "      <td>352</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2003</td>\n",
              "      <td>32.0</td>\n",
              "      <td>5-3-2</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.086207</td>\n",
              "      <td>...</td>\n",
              "      <td>0.371473</td>\n",
              "      <td>0.356322</td>\n",
              "      <td>0.464706</td>\n",
              "      <td>0.272321</td>\n",
              "      <td>Defender</td>\n",
              "      <td>Left-Back</td>\n",
              "      <td>left</td>\n",
              "      <td>8.000000e+05</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3333</td>\n",
              "      <td>352</td>\n",
              "      <td>399</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2003</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4-1-4-1</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>...</td>\n",
              "      <td>0.620690</td>\n",
              "      <td>0.241379</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>Attack</td>\n",
              "      <td>Centre-Forward</td>\n",
              "      <td>right</td>\n",
              "      <td>5.500000e+07</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3333</td>\n",
              "      <td>399</td>\n",
              "      <td>762</td>\n",
              "      <td>7400000.0</td>\n",
              "      <td>7400000.0</td>\n",
              "      <td>2004</td>\n",
              "      <td>255.0</td>\n",
              "      <td>4-3-3 Attacking</td>\n",
              "      <td>501.0</td>\n",
              "      <td>0.060938</td>\n",
              "      <td>...</td>\n",
              "      <td>0.679278</td>\n",
              "      <td>0.161885</td>\n",
              "      <td>0.767983</td>\n",
              "      <td>0.580309</td>\n",
              "      <td>Midfield</td>\n",
              "      <td>Central Midfield</td>\n",
              "      <td>right</td>\n",
              "      <td>2.966667e+07</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3333</td>\n",
              "      <td>762</td>\n",
              "      <td>405</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5500000.0</td>\n",
              "      <td>2005</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3-4-1-2</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>Defender</td>\n",
              "      <td>Left-Back</td>\n",
              "      <td>left</td>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>19.0</td>\n",
              "      <td>-5500000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   player_id  from_club_id  to_club_id  transfer_fee  market_value_in_eur  \\\n",
              "0       3333         10161         399           0.0                  0.0   \n",
              "1       3333           399         352           0.0                  0.0   \n",
              "2       3333           352         399           0.0                  0.0   \n",
              "3       3333           399         762     7400000.0            7400000.0   \n",
              "4       3333           762         405           0.0            5500000.0   \n",
              "\n",
              "   season  home_games playing_formation  appearances  goals_per_game  ...  \\\n",
              "0    2002        35.0           4-2-3-1         68.0        0.000000  ...   \n",
              "1    2003        32.0             5-3-2         62.0        0.086207  ...   \n",
              "2    2003        15.0           4-1-4-1         29.0        0.137931  ...   \n",
              "3    2004       255.0   4-3-3 Attacking        501.0        0.060938  ...   \n",
              "4    2005        12.0           3-4-1-2         28.0        0.000000  ...   \n",
              "\n",
              "   win_percentage  draw_percentage  home_win_percentage  away_win_percentage  \\\n",
              "0        0.208333         0.263889             0.316993             0.088889   \n",
              "1        0.371473         0.356322             0.464706             0.272321   \n",
              "2        0.620690         0.241379             0.866667             0.357143   \n",
              "3        0.679278         0.161885             0.767983             0.580309   \n",
              "4        0.035714         0.250000             0.000000             0.062500   \n",
              "\n",
              "     position      sub_position   foot  avg_market_value_of_last_seasons  \\\n",
              "0  Goalkeeper        Goalkeeper   left                      1.500000e+06   \n",
              "1    Defender         Left-Back   left                      8.000000e+05   \n",
              "2      Attack    Centre-Forward  right                      5.500000e+07   \n",
              "3    Midfield  Central Midfield  right                      2.966667e+07   \n",
              "4    Defender         Left-Back   left                      1.000000e+06   \n",
              "\n",
              "  age_at_transfer transfer_diff  \n",
              "0            16.0           0.0  \n",
              "1            17.0           0.0  \n",
              "2            17.0           0.0  \n",
              "3            18.0           0.0  \n",
              "4            19.0    -5500000.0  \n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transfer_data = pd.read_csv(\"C:\\\\Users\\\\devdp\\\\OneDrive\\\\Documents\\\\Github\\\\UMBC\\\\soccer_master\\\\data\\\\transfers_data.csv\")\n",
        "transfer_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lRB6HZ72d0tg"
      },
      "outputs": [],
      "source": [
        "def process_formation_data(dataframe, training_year_threshold):\n",
        "    \"\"\"\n",
        "    Process and standardize formation data by replacing rare formations.\n",
        "\n",
        "    Args:\n",
        "        dataframe: Transfer data DataFrame\n",
        "        training_year_threshold: Year to split training data\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with processed formation data\n",
        "    \"\"\"\n",
        "    processed_df = dataframe.copy()\n",
        "\n",
        "    # Identify common formations (10+ occurrences) in training data\n",
        "    formation_frequency = processed_df[processed_df['season'] < training_year_threshold]['playing_formation'].value_counts()\n",
        "    frequent_formations = formation_frequency[formation_frequency >= 10].index\n",
        "\n",
        "    # Standardize rare and missing formations\n",
        "    processed_df.loc[~processed_df['playing_formation'].isin(frequent_formations), 'playing_formation'] = 'Other'\n",
        "    processed_df['playing_formation'] = processed_df['playing_formation'].fillna('Unknown')\n",
        "\n",
        "    return processed_df\n",
        "\n",
        "def prepare_model_data(dataframe, training_year_threshold=2023):\n",
        "    \"\"\"\n",
        "    Prepare data for model training by splitting and identifying feature types.\n",
        "\n",
        "    Args:\n",
        "        dataframe: Transfer data DataFrame\n",
        "        training_year_threshold: Year to split training/test data (default: 2023)\n",
        "\n",
        "    Returns:\n",
        "        X_train, X_test, y_train, y_test, categorical_features, numerical_features\n",
        "    \"\"\"\n",
        "    processed_df = process_formation_data(dataframe, training_year_threshold)\n",
        "\n",
        "    # Split data by year\n",
        "    train_data = processed_df[processed_df['season'] < training_year_threshold].copy()\n",
        "    test_data = processed_df[processed_df['season'] >= training_year_threshold].copy()\n",
        "\n",
        "    # Separate features and target\n",
        "    X_train = train_data.drop(['transfer_fee'], axis=1)\n",
        "    y_train = np.array(train_data['transfer_fee'])\n",
        "    X_test = test_data.drop(['transfer_fee'], axis=1)\n",
        "    y_test = np.array(test_data['transfer_fee'])\n",
        "\n",
        "    # Identify feature types\n",
        "    categorical_features = ['position', 'sub_position', 'foot', 'playing_formation']\n",
        "    numerical_features = [col for col in X_train.columns if col not in categorical_features]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, categorical_features, numerical_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Lhe25EiXd_ZE"
      },
      "outputs": [],
      "source": [
        "def transform_features(features_df, categorical_columns, numerical_columns, existing_transformer=None):\n",
        "    \"\"\"\n",
        "    Transform features using preprocessing pipeline for model training/inference.\n",
        "\n",
        "    Args:\n",
        "        features_df: Feature DataFrame\n",
        "        categorical_columns: List of categorical feature names\n",
        "        numerical_columns: List of numerical feature names\n",
        "        existing_transformer: Optional fitted transformer for inference\n",
        "\n",
        "    Returns:\n",
        "        transformed_features: Preprocessed feature matrix\n",
        "        transformer: Fitted transformer pipeline\n",
        "    \"\"\"\n",
        "    feature_preprocessor = ColumnTransformer([\n",
        "        ('numerical', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numerical_columns),\n",
        "        ('categorical', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "            ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
        "        ]), categorical_columns)\n",
        "    ])\n",
        "\n",
        "    preprocessing_pipeline = Pipeline([\n",
        "        ('preprocessor', feature_preprocessor),\n",
        "    ])\n",
        "\n",
        "    if existing_transformer is None:\n",
        "        transformed_features = preprocessing_pipeline.fit_transform(features_df)\n",
        "        return transformed_features, preprocessing_pipeline\n",
        "    else:\n",
        "        transformed_features = existing_transformer.transform(features_df)\n",
        "        return transformed_features, existing_transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0Hjhm1NeWY0"
      },
      "source": [
        "### Data Preparation Pipeline\n",
        "\n",
        "1. Split data into training/test sets (Using transfers before 2021 as training and rest as test data)\n",
        "2. Transform features using preprocessing pipeline\n",
        "3. Ensure consistent preprocessing across train/test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0RwkXoIcXe2",
        "outputId": "16c233de-5a1b-44ec-b240-17af4a118cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initiating data preparation pipeline...\n",
            "\n",
            "Data preparation pipeline initiated successfully!\n",
            "✓ Data split complete: 46502 training samples, 15067 test samples\n",
            "✓ Training data transformed: 66 features generated\n",
            "✓ Test data transformed: 66 features generated\n",
            "\n",
            "Data preparation completed successfully!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nInitiating data preparation pipeline...\")\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test, categorical_features, numerical_features = prepare_model_data(transfer_data, training_year_threshold=2021)\n",
        "\n",
        "print(\"\\nData preparation pipeline initiated successfully!\")\n",
        "print(f\"✓ Data split complete: {len(X_train)} training samples, {len(X_test)} test samples\")\n",
        "\n",
        "# Transform training data and get fitted transformer\n",
        "X_train_transformed, feature_transformer = transform_features(\n",
        "    X_train,\n",
        "    categorical_features,\n",
        "    numerical_features\n",
        ")\n",
        "print(f\"✓ Training data transformed: {X_train_transformed.shape[1]} features generated\")\n",
        "\n",
        "# Transform test data using fitted transformer\n",
        "X_test_transformed, _ = transform_features(\n",
        "    X_test,\n",
        "    categorical_features,\n",
        "    numerical_features,\n",
        "    existing_transformer=feature_transformer\n",
        ")\n",
        "\n",
        "target_scaler = StandardScaler()\n",
        "target_scaler.fit(y_train.reshape(-1, 1))  # Ensure y_train is 2D\n",
        "\n",
        "y_train_transformed = target_scaler.transform(y_train.reshape(-1, 1))\n",
        "y_test_transformed = target_scaler.transform(y_test.reshape(-1, 1))\n",
        "\n",
        "\n",
        "print(f\"✓ Test data transformed: {X_test_transformed.shape[1]} features generated\")\n",
        "\n",
        "print(\"\\nData preparation completed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Defining neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining **Layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Layer(ABC):\n",
        "    \"\"\"The base class for NN model layer\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    \n",
        "    @abstractmethod\n",
        "    def forward(self, x):\n",
        "        raise NotImplementedError\n",
        "    \n",
        "    @abstractmethod\n",
        "    def backward(self, dout):\n",
        "        raise NotImplementedError\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining **Linear** layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Linear(Layer):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        self.params = {}\n",
        "        self.params['W'] = np.random.randn(input_dim, output_dim) / np.sqrt(input_dim)  # normalized weights\n",
        "        self.params['b'] = np.random.randn(output_dim)\n",
        "\n",
        "        self.grads = {}\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        \n",
        "        out = np.dot(x, self.params['W']) + self.params['b']\n",
        "        \n",
        "        return out \n",
        "\n",
        "    def backward(self, dout):\n",
        "\n",
        "        self.grads['W'] = np.dot(self.x.T, dout)\n",
        "        self.grads['b'] = np.sum(dout, axis=0)\n",
        "\n",
        "        return np.dot(dout, self.params['W'].T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining **ReLU** activation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ReLU(Layer):\n",
        "    def __init__(self):\n",
        "        self.params = None\n",
        "    \n",
        "    def forward(self, x):\n",
        "        self.mask = (x<=0)\n",
        "        out = x.copy()\n",
        "        out[self.mask] = 0\n",
        "        \n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = dout.copy()  # Avoid modifying input gradient directly\n",
        "        dx[self.mask] = 0\n",
        "        return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining Output layer with linear activation and Mean squared error loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LinearWithMSE(Layer):\n",
        "    def __init__(self):\n",
        "        self.params = None\n",
        "\n",
        "    def forward(self, out, y):\n",
        "        '''\n",
        "            out: predicted values\n",
        "            y: true labels\n",
        "        '''\n",
        "        # batch_size = out.shape[0]\n",
        "        self.out = out\n",
        "        self.y = y\n",
        "        \n",
        "        loss = np.mean((out - y) ** 2)\n",
        "        return loss, out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        batch_size = self.y.shape[0]\n",
        "        return (2 * (self.out - self.y)) / batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining **Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FNN(Layer):\n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "        self.layers.append(Linear(66, 40))\n",
        "        self.layers.append(ReLU())\n",
        "        self.layers.append(Linear(40, 20))\n",
        "        self.layers.append(ReLU())\n",
        "        self.layers.append(Linear(20, 1))\n",
        "        self.layers.append(LinearWithMSE())\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        batch_size = x.shape[0]\n",
        "        \n",
        "        x = x.reshape(batch_size, 66)\n",
        "\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = layer.forward(x)\n",
        "        \n",
        "        return self.layers[-1].forward(x, y)\n",
        "\n",
        "    def predict(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        \n",
        "        x = x.reshape(batch_size, 66)\n",
        "\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = layer.forward(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def backward(self):\n",
        "        dout = self.layers[-1].backward(1)\n",
        "        for layer in self.layers[::-1]:\n",
        "            dout = layer.backward(dout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining base **Optimizer** class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Optimizer(ABC):\n",
        "    \"\"\"The base class for optimizer.\"\"\"\n",
        "    def __init__(self, learning_rate, layers):\n",
        "        super().__init__()\n",
        "\n",
        "    @abstractmethod\n",
        "    def update(self):\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining **Stochastic Gradient Descent** optimizer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SGD(Optimizer):\n",
        "    \"\"\"SGD (Stochastic Gradient Descent) optimizer\"\"\"\n",
        "    def __init__(self, learning_rate, layers):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.layers = layers\n",
        "\n",
        "    def update(self):\n",
        "        for layer in self.layers:\n",
        "            if hasattr(layer, 'params') and layer.params is not None:\n",
        "                for key in layer.params.keys():\n",
        "                    layer.params[key] -= self.learning_rate * layer.grads[key]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# prompt: provide a generator to provide data as batches to  model\n",
        "\n",
        "def data_generator(data, label, batch_size):\n",
        "  \"\"\"\n",
        "  Generates batches of data and labels.\n",
        "\n",
        "  Args:\n",
        "    data: The input data.\n",
        "    label: The corresponding labels.\n",
        "    batch_size: The size of each batch.\n",
        "\n",
        "  Yields:\n",
        "    A tuple of (data_batch, label_batch).\n",
        "  \"\"\"\n",
        "  num_samples = len(data)\n",
        "  num_batches = num_samples // batch_size\n",
        "\n",
        "  for i in range(num_batches):\n",
        "    start = i * batch_size\n",
        "    end = (i + 1) * batch_size\n",
        "    yield data[start:end], label[start:end]\n",
        "\n",
        "  # If there are remaining samples, yield a smaller batch.\n",
        "  if num_samples % batch_size != 0:\n",
        "    yield data[num_batches * batch_size:], label[num_batches * batch_size:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_data, train_label, epochs, batch_size):\n",
        "  \"\"\"\n",
        "  Trains and validates a neural network model.\n",
        "\n",
        "  Args:\n",
        "    model: The neural network model.\n",
        "    optimizer: The optimizer used for training.\n",
        "    train_data: The training data.\n",
        "    train_label: The training labels.\n",
        "    epochs: The number of training epochs.\n",
        "    batch_size: The batch size for training.\n",
        "  \"\"\"\n",
        "  for epoch in range(epochs):\n",
        "    # Shuffle training data for each epoch\n",
        "    train_data, train_label = shuffle(train_data, train_label)\n",
        "\n",
        "    # Training loop\n",
        "    train_loss = 0\n",
        "    # train_correct = 0\n",
        "    for data_batch, label_batch in iter(data_generator(train_data, train_label, batch_size)):\n",
        "      loss, output = model.forward(data_batch, label_batch)\n",
        "      train_loss += loss * data_batch.shape[0]    # Scale loss by batch size\n",
        "      \n",
        "      # train_correct += np.sum(np.argmax(output, axis=1) == label_batch)\n",
        "      model.backward()\n",
        "      optimizer.update()\n",
        "\n",
        "    # Validation loop\n",
        "    valid_loss = 0\n",
        "    # valid_correct = 0\n",
        "    # for data_batch, label_batch in data_generator(valid_data, valid_label, batch_size):\n",
        "    #   loss, output = model.forward(data_batch, label_batch)\n",
        "    #   valid_loss += loss\n",
        "    #   # valid_correct += np.sum(np.argmax(output, axis=1) == label_batch)\n",
        "\n",
        "    print(f'Epoch: {epoch + 1}/{epochs}, Train Loss: {train_loss / len(train_data):.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(model, test_data, test_label, batch_size=1):\n",
        "  \"\"\"\n",
        "  Tests the neural network model on the test dataset.\n",
        "\n",
        "  Args:\n",
        "    model: The neural network model.\n",
        "    test_data: The test data.\n",
        "    test_label: The test labels.\n",
        "    batch_size: The batch size for testing.\n",
        "  \"\"\"\n",
        "  mae = 0\n",
        "  for data_batch, label_batch in data_generator(test_data, test_label, batch_size):\n",
        "    loss, output = model.forward(data_batch, label_batch)\n",
        "    mae += loss * data_batch.shape[0]\n",
        "\n",
        "  print(f'Test Acc: {1 - (mae / len(test_data)):.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/100, Train Loss: 0.2432\n",
            "Epoch: 2/100, Train Loss: 0.0083\n",
            "Epoch: 3/100, Train Loss: 0.0036\n",
            "Epoch: 4/100, Train Loss: 0.0024\n",
            "Epoch: 5/100, Train Loss: 0.0015\n",
            "Epoch: 6/100, Train Loss: 0.0014\n",
            "Epoch: 7/100, Train Loss: 0.0010\n",
            "Epoch: 8/100, Train Loss: 0.0008\n",
            "Epoch: 9/100, Train Loss: 0.0008\n",
            "Epoch: 10/100, Train Loss: 0.0007\n",
            "Epoch: 11/100, Train Loss: 0.0005\n",
            "Epoch: 12/100, Train Loss: 0.0005\n",
            "Epoch: 13/100, Train Loss: 0.0004\n",
            "Epoch: 14/100, Train Loss: 0.0004\n",
            "Epoch: 15/100, Train Loss: 0.0004\n",
            "Epoch: 16/100, Train Loss: 0.0003\n",
            "Epoch: 17/100, Train Loss: 0.0004\n",
            "Epoch: 18/100, Train Loss: 0.0003\n",
            "Epoch: 19/100, Train Loss: 0.0003\n",
            "Epoch: 20/100, Train Loss: 0.0003\n",
            "Epoch: 21/100, Train Loss: 0.0002\n",
            "Epoch: 22/100, Train Loss: 0.0002\n",
            "Epoch: 23/100, Train Loss: 0.0002\n",
            "Epoch: 24/100, Train Loss: 0.0002\n",
            "Epoch: 25/100, Train Loss: 0.0002\n",
            "Epoch: 26/100, Train Loss: 0.0002\n",
            "Epoch: 27/100, Train Loss: 0.0002\n",
            "Epoch: 28/100, Train Loss: 0.0002\n",
            "Epoch: 29/100, Train Loss: 0.0001\n",
            "Epoch: 30/100, Train Loss: 0.0001\n",
            "Epoch: 31/100, Train Loss: 0.0001\n",
            "Epoch: 32/100, Train Loss: 0.0001\n",
            "Epoch: 33/100, Train Loss: 0.0001\n",
            "Epoch: 34/100, Train Loss: 0.0001\n",
            "Epoch: 35/100, Train Loss: 0.0001\n",
            "Epoch: 36/100, Train Loss: 0.0001\n",
            "Epoch: 37/100, Train Loss: 0.0001\n",
            "Epoch: 38/100, Train Loss: 0.0001\n",
            "Epoch: 39/100, Train Loss: 0.0001\n",
            "Epoch: 40/100, Train Loss: 0.0001\n",
            "Epoch: 41/100, Train Loss: 0.0001\n",
            "Epoch: 42/100, Train Loss: 0.0001\n",
            "Epoch: 43/100, Train Loss: 0.0001\n",
            "Epoch: 44/100, Train Loss: 0.0001\n",
            "Epoch: 45/100, Train Loss: 0.0001\n",
            "Epoch: 46/100, Train Loss: 0.0001\n",
            "Epoch: 47/100, Train Loss: 0.0002\n",
            "Epoch: 48/100, Train Loss: 0.0001\n",
            "Epoch: 49/100, Train Loss: 0.0001\n",
            "Epoch: 50/100, Train Loss: 0.0001\n",
            "Epoch: 51/100, Train Loss: 0.0001\n",
            "Epoch: 52/100, Train Loss: 0.0001\n",
            "Epoch: 53/100, Train Loss: 0.0001\n",
            "Epoch: 54/100, Train Loss: 0.0001\n",
            "Epoch: 55/100, Train Loss: 0.0001\n",
            "Epoch: 56/100, Train Loss: 0.0001\n",
            "Epoch: 57/100, Train Loss: 0.0001\n",
            "Epoch: 58/100, Train Loss: 0.0001\n",
            "Epoch: 59/100, Train Loss: 0.0001\n",
            "Epoch: 60/100, Train Loss: 0.0001\n",
            "Epoch: 61/100, Train Loss: 0.0001\n",
            "Epoch: 62/100, Train Loss: 0.0001\n",
            "Epoch: 63/100, Train Loss: 0.0001\n",
            "Epoch: 64/100, Train Loss: 0.0001\n",
            "Epoch: 65/100, Train Loss: 0.0001\n",
            "Epoch: 66/100, Train Loss: 0.0000\n",
            "Epoch: 67/100, Train Loss: 0.0001\n",
            "Epoch: 68/100, Train Loss: 0.0000\n",
            "Epoch: 69/100, Train Loss: 0.0000\n",
            "Epoch: 70/100, Train Loss: 0.0001\n",
            "Epoch: 71/100, Train Loss: 0.0000\n",
            "Epoch: 72/100, Train Loss: 0.0000\n",
            "Epoch: 73/100, Train Loss: 0.0000\n",
            "Epoch: 74/100, Train Loss: 0.0000\n",
            "Epoch: 75/100, Train Loss: 0.0000\n",
            "Epoch: 76/100, Train Loss: 0.0000\n",
            "Epoch: 77/100, Train Loss: 0.0000\n",
            "Epoch: 78/100, Train Loss: 0.0000\n",
            "Epoch: 79/100, Train Loss: 0.0000\n",
            "Epoch: 80/100, Train Loss: 0.0000\n",
            "Epoch: 81/100, Train Loss: 0.0000\n",
            "Epoch: 82/100, Train Loss: 0.0000\n",
            "Epoch: 83/100, Train Loss: 0.0000\n",
            "Epoch: 84/100, Train Loss: 0.0000\n",
            "Epoch: 85/100, Train Loss: 0.0000\n",
            "Epoch: 86/100, Train Loss: 0.0001\n",
            "Epoch: 87/100, Train Loss: 0.0000\n",
            "Epoch: 88/100, Train Loss: 0.0000\n",
            "Epoch: 89/100, Train Loss: 0.0000\n",
            "Epoch: 90/100, Train Loss: 0.0000\n",
            "Epoch: 91/100, Train Loss: 0.0000\n",
            "Epoch: 92/100, Train Loss: 0.0000\n",
            "Epoch: 93/100, Train Loss: 0.0000\n",
            "Epoch: 94/100, Train Loss: 0.0000\n",
            "Epoch: 95/100, Train Loss: 0.0000\n",
            "Epoch: 96/100, Train Loss: 0.0000\n",
            "Epoch: 97/100, Train Loss: 0.0000\n",
            "Epoch: 98/100, Train Loss: 0.0000\n",
            "Epoch: 99/100, Train Loss: 0.0000\n",
            "Epoch: 100/100, Train Loss: 0.0000\n"
          ]
        }
      ],
      "source": [
        "model_fnn = FNN()\n",
        "learning_rate = 0.1\n",
        "epochs = 100\n",
        "batch_size = 256\n",
        "optimizer = SGD(learning_rate, model_fnn.layers)\n",
        "\n",
        "train(model_fnn, optimizer, X_train_transformed, np.array(y_train_transformed).reshape(-1,1), epochs, batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Acc: 0.9999\n"
          ]
        }
      ],
      "source": [
        "test(model_fnn, X_test_transformed, np.array(y_test_transformed).reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_currency(number):\n",
        "    \"\"\"\n",
        "    Format number as currency with thousands separators (e.g., 35,000,000)\n",
        "    \"\"\"\n",
        "    return \"{:,.0f}\".format(number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_player_transfer(player_id, data, model, transformer, categorical_cols, numerical_cols):\n",
        "    \"\"\"\n",
        "    Predict transfer fee for a specific player\n",
        "    \"\"\"\n",
        "    # Get player data\n",
        "    player_data = data.query(f'player_id=={player_id}').iloc[1]\n",
        "    actual_fee = player_data[\"transfer_fee\"]\n",
        "\n",
        "    # Prepare features\n",
        "    features = pd.DataFrame(player_data.drop(\"transfer_fee\")).T\n",
        "    transformed_features, _ = transform_features(\n",
        "        features,\n",
        "        categorical_cols,\n",
        "        numerical_cols,\n",
        "        existing_transformer=transformer\n",
        "    )\n",
        "\n",
        "    # Predict on the scaled data\n",
        "    y_pred_scaled = model.predict(transformed_features)  # Get the output (scaled prediction)\n",
        "\n",
        "    # Ensure it's in the correct shape before inverse transforming\n",
        "    y_pred_original = target_scaler.inverse_transform(y_pred_scaled.reshape(1, -1)).reshape(-1)[0]\n",
        "\n",
        "    print(f\"\\nTransfer Fee Prediction:\")\n",
        "    print(f\"Predicted: {format_currency(y_pred_original)} euros\")\n",
        "    print(f\"Actual: {format_currency(actual_fee)} euros\")\n",
        "    print(f\"Difference: {format_currency(abs(y_pred_original - actual_fee))} euros\")\n",
        "\n",
        "    return y_pred_original, actual_fee"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Transfer Fee Prediction:\n",
            "Predicted: 55,175,079 euros\n",
            "Actual: 55,000,000 euros\n",
            "Difference: 175,079 euros\n"
          ]
        }
      ],
      "source": [
        "# Predict transfer fee\n",
        "predicted_fee, actual_fee = predict_player_transfer(\n",
        "    288230,\n",
        "    transfer_data,\n",
        "    model_fnn,\n",
        "    feature_transformer,\n",
        "    categorical_features,\n",
        "    numerical_features\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
